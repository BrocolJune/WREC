{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17df5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio numpy pandas tqdm pvlib geopandas shapely matplotlib openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.vrt import WarpedVRT\n",
    "import os\n",
    "\n",
    "def calculate_slope_aspect(dem, transform):\n",
    "    # ... (생략: 기존 구현 그대로)\n",
    "    x, y = np.gradient(dem, 30, 30)\n",
    "    slope = np.pi/2 - np.arctan(np.hypot(x, y))\n",
    "    aspect = np.arctan2(-x, y)\n",
    "    aspect = np.where(aspect < 0, 2*np.pi + aspect, aspect)\n",
    "    return slope, aspect\n",
    "\n",
    "def generate_hillshade_tifs(input_dem, slope_tif, aspect_tif, target_crs=\"EPSG:32652\"):\n",
    "    # 1) DEM → 가상 UTM(메모리 reprojection)\n",
    "    with rasterio.open(input_dem) as src:\n",
    "        vrt_params = {\n",
    "            \"crs\": target_crs,\n",
    "            \"resampling\": rasterio.enums.Resampling.bilinear,\n",
    "            \"resolution\": (30, 30)\n",
    "        }\n",
    "        with WarpedVRT(src, **vrt_params) as vrt:\n",
    "            dem = vrt.read(1).astype(\"float64\")\n",
    "            transform = vrt.transform\n",
    "\n",
    "            # 2) slope, aspect 계산\n",
    "            slope_rad, aspect_rad = calculate_slope_aspect(dem, transform)\n",
    "\n",
    "            # 라디안 → 도 단위 변환\n",
    "            slope_deg  = np.degrees(slope_rad)         # 0°~90°\n",
    "            aspect_deg = np.degrees(aspect_rad) % 360  # 0°~360°\n",
    "\n",
    "            # 이제 slope_deg, aspect_deg 를 GeoTIFF 로 저장하거나\n",
    "            # 힐셰이드·분석 등에 바로 활용하세요.\n",
    "            # 3) 메타데이터 준비 (driver만 GTiff 로 강제)\n",
    "            meta = vrt.meta.copy()\n",
    "            meta.update({\n",
    "                \"driver\": \"GTiff\",     # ← 이 줄이 필수\n",
    "                \"dtype\": \"float32\",\n",
    "                \"count\": 1,\n",
    "                \"nodata\": None\n",
    "            })\n",
    "\n",
    "            # 4) slope 저장\n",
    "            with rasterio.open(slope_tif, \"w\", **meta) as dst:\n",
    "                dst.write(slope_deg.astype(\"float32\"), 1)\n",
    "\n",
    "            # 5) aspect 저장\n",
    "            with rasterio.open(aspect_tif, \"w\", **meta) as dst:\n",
    "                dst.write(aspect_deg.astype(\"float32\"), 1)\n",
    "\n",
    "    print(\"완료: Slope & Aspect GeoTIFF 생성\")\n",
    "\n",
    "# 사용 예시\n",
    "input_dem  = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Clip.tif\"\n",
    "slope_tif  = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Slope.tif\"\n",
    "aspect_tif = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Aspect.tif\"\n",
    "generate_hillshade_tifs(input_dem, slope_tif, aspect_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pvlib import solarposition\n",
    "\n",
    "def calculate_slope_aspect(dem, transform):\n",
    "    # 경사도(slope), 방향(aspect) 계산 (단위: 라디안)\n",
    "    x, y = np.gradient(dem, 30, 30)  # 30m 해상도 기준\n",
    "    slope = np.pi/2 - np.arctan(np.sqrt(x*x + y*y))\n",
    "    aspect = np.arctan2(-x, y)\n",
    "    aspect = np.where(aspect < 0, 2 * np.pi + aspect, aspect)\n",
    "    return slope, aspect\n",
    "\n",
    "def compute_hillshade(slope, aspect, azimuth_deg, altitude_deg):\n",
    "    # 태양 방위각, 고도각 → 라디안 변환\n",
    "    azimuth_rad = np.radians(azimuth_deg)\n",
    "    altitude_rad = np.radians(altitude_deg)\n",
    "    \n",
    "    shaded = (np.sin(altitude_rad) * np.sin(slope) +\n",
    "              np.cos(altitude_rad) * np.cos(slope) * np.cos(azimuth_rad - aspect))\n",
    "    \n",
    "    shaded = np.clip(shaded, 0, 1)  # 0~1 범위로 정리\n",
    "    return shaded * 255  # 🎯 0~255 범위로 변환\n",
    "\n",
    "def generate_hourly_hillshades(dem_path, solar_csv_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # DEM 로드\n",
    "    with rasterio.open(dem_path) as dem_src:\n",
    "        dem = dem_src.read(1)\n",
    "        meta = dem_src.meta.copy()\n",
    "        transform = dem_src.transform\n",
    "    \n",
    "    # slope & aspect 계산\n",
    "    slope, aspect = calculate_slope_aspect(dem, transform)\n",
    "\n",
    "    # 태양 위치 데이터 로드\n",
    "    solar_df = pd.read_csv(solar_csv_path, parse_dates=['datetime'])\n",
    "\n",
    "    # Hillshade 계산\n",
    "    for _, row in tqdm(solar_df.iterrows(), total=len(solar_df)):\n",
    "        dt = row['datetime']\n",
    "        elev = row['elevation']\n",
    "        azim = row['azimuth']\n",
    "\n",
    "        if elev <= 0:\n",
    "            continue  # 태양이 떠 있지 않으면 저장하지 않음\n",
    "\n",
    "        hillshade = compute_hillshade(slope, aspect, azim, elev)  # 0~255\n",
    "\n",
    "        # 저장 경로 생성\n",
    "        fname = f\"hillshade_{dt.strftime('%Y-%m-%d_%H-%M')}.tif\"\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        # 저장 (GeoTIFF, uint8, WGS84)\n",
    "        meta.update(dtype='uint8', count=1)\n",
    "        with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "            dst.write(hillshade.astype('uint8'), 1)\n",
    "\n",
    "    print(f\"Hillshade 생성 완료 (0~255 스케일, 태양이 뜬 시간만): {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 사용 예시 (경로 설정)\n",
    "dem_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Naju_DEM_Clip.tif\"\n",
    "solar_csv_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\solar_position_naju.csv\"\n",
    "output_dir = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Hillshade_naju\"\n",
    "\n",
    "generate_hourly_hillshades(dem_path, solar_csv_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hillshade_Band approach\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from affine import Affine\n",
    "from pvlib.location import Location\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pvlib.solarposition import get_solarposition\n",
    "\n",
    "\n",
    "def calculate_slope_aspect(dem):\n",
    "    x, y = np.gradient(dem, 90, 90)\n",
    "    slope = np.pi / 2 - np.arctan(np.sqrt(x*x + y*y))\n",
    "    aspect = np.arctan2(-x, y)\n",
    "    aspect = np.where(aspect < 0, 2 * np.pi + aspect, aspect)\n",
    "    return slope, aspect\n",
    "\n",
    "\n",
    "def compute_hillshade(slope, aspect, azimuth_deg, altitude_deg):\n",
    "    azimuth_rad = np.radians(azimuth_deg)\n",
    "    altitude_rad = np.radians(altitude_deg)\n",
    "    shaded = (np.sin(altitude_rad) * np.sin(slope) +\n",
    "              np.cos(altitude_rad) * np.cos(slope) * np.cos(azimuth_rad - aspect))\n",
    "    shaded = np.clip(shaded, 0, 1)\n",
    "    return (shaded * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_lat_band_masks(dem_data, transform, bands):\n",
    "    rows, cols = dem_data.shape\n",
    "    lats = np.empty((rows, cols))\n",
    "    for r in range(rows):\n",
    "        _, lat_row = xy(transform, r, 0)\n",
    "        lats[r, :] = lat_row  # 모든 열에 동일한 위도\n",
    "    return {b: (lats >= b[0]) & (lats < b[1]) for b in bands}\n",
    "\n",
    "\n",
    "def precompute_solar_positions(bands, lon, times):\n",
    "    solar_dict = {}\n",
    "    for (lat_min, lat_max) in bands:\n",
    "        center_lat = (lat_min + lat_max) / 2\n",
    "        key = (lat_min, lat_max)\n",
    "        solar_pos = get_solarposition(times, center_lat, lon)\n",
    "        solar_dict[key] = solar_pos[['apparent_elevation', 'azimuth']]\n",
    "    return solar_dict\n",
    "\n",
    "\n",
    "def generate_combined_hillshades(dem_path, output_dir, solar_dict, bands, times):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with rasterio.open(dem_path) as src:\n",
    "        dem = src.read(1)\n",
    "        transform = src.transform\n",
    "        meta = src.meta.copy()\n",
    "\n",
    "    meta.update(dtype='uint8', count=1, nodata=0)\n",
    "\n",
    "    slope, aspect = calculate_slope_aspect(dem)\n",
    "    masks = get_lat_band_masks(dem, transform, bands)\n",
    "\n",
    "    for dt in tqdm(times, desc=\"Generating hillshades\"):\n",
    "        combined = np.zeros_like(dem, dtype='uint8')\n",
    "        valid_band = False\n",
    "\n",
    "        for (lat_min, lat_max), mask in masks.items():\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            sol_data = solar_dict[(lat_min, lat_max)].loc[dt]\n",
    "            elev, azim = sol_data['apparent_elevation'], sol_data['azimuth']\n",
    "\n",
    "            if elev <= 0:\n",
    "                continue\n",
    "\n",
    "            hs = compute_hillshade(slope, aspect, azim, elev)\n",
    "            combined = np.where(mask, hs, combined)\n",
    "            valid_band = True\n",
    "\n",
    "        if not valid_band:\n",
    "            print(f\"⚠️ {dt} - 모든 밴드에서 유효 고도각 없음 → 파일 저장 생략\")\n",
    "            continue\n",
    "\n",
    "        fname = f\"hillshade_combined_{dt.strftime('%Y-%m-%d_%H-%M')}.tif\"\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "            dst.write(combined, 1)\n",
    "\n",
    "        print(f\"✅ 저장 완료: {fname}\")\n",
    "\n",
    "\n",
    "dem_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korean Peninsula\\Korea90m_GRS80.img\"\n",
    "output_dir = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korea_hillshade\"\n",
    "\n",
    "bands = [(33, 34), (34, 35), (35, 36), (36, 37), (37, 38)]\n",
    "\n",
    "times = pd.date_range(start='2023-01-01 00:00', end='2023-12-31 23:00', freq='1h', tz='Asia/Seoul')\n",
    "solar_dict = precompute_solar_positions(bands, lon=126.5, times=times, output_dir = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korea_hillshade\")\n",
    "\n",
    "\n",
    "\n",
    "generate_combined_hillshades(dem_path, output_dir, solar_dict, bands, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c487af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hillshade_utils.py\n",
    "import numpy as np\n",
    "\n",
    "def compute_slope_aspect(dem, transform):\n",
    "    x, y = np.gradient(dem.astype('float64'))\n",
    "    slope = np.arctan(np.sqrt(x**2 + y**2))\n",
    "    aspect = np.arctan2(-x, y)\n",
    "    aspect = np.mod(aspect, 2 * np.pi)\n",
    "    return slope, aspect\n",
    "\n",
    "def compute_hillshade(slope, aspect, azimuth_deg, altitude_deg):\n",
    "    azimuth_rad = np.radians(360 - azimuth_deg + 90)\n",
    "    altitude_rad = np.radians(altitude_deg)\n",
    "\n",
    "    shaded = (np.cos(altitude_rad) * np.cos(slope) +\n",
    "              np.sin(altitude_rad) * np.sin(slope) * np.cos(azimuth_rad - aspect))\n",
    "    shaded = np.clip(shaded, 0, 1)\n",
    "    return (shaded * 255).astype(np.uint8)\n",
    "\n",
    "def get_lat_band_masks(dem, transform, lat_band_edges):\n",
    "    masks = {}\n",
    "    height, width = dem.shape\n",
    "    rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "    \n",
    "    lats = transform.f + rows * transform.e  # y축 방향 변화량으로부터 위도 계산\n",
    "    for i in range(len(lat_band_edges) - 1):\n",
    "        lat_min, lat_max = lat_band_edges[i], lat_band_edges[i+1]\n",
    "        mask = (lats >= lat_min) & (lats < lat_max)\n",
    "        masks[(lat_min, lat_max)] = mask\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solar dictionary 생성\n",
    "from pvlib.solarposition import get_solarposition\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# 타임존 설정\n",
    "tz = 'Asia/Seoul'\n",
    "\n",
    "# 시간 범위 생성: 2023년 1년, 1시간 간격\n",
    "times = pd.date_range(start=\"2023-01-01 00:00\", end=\"2023-12-31 21:00\", freq=\"3H\", tz=tz)\n",
    "\n",
    "# 위도 밴드 정의\n",
    "lat_bands = [(33, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39)]\n",
    "\n",
    "# 임의의 중심 경도 설정 (예: 한국 중심)\n",
    "lon = 127.5\n",
    "\n",
    "# solar_dict 초기화\n",
    "solar_dict = {}\n",
    "\n",
    "# 위도 밴드별로 solar position 계산\n",
    "for (lat_min, lat_max) in lat_bands:\n",
    "    lat_center = (lat_min + lat_max) / 2  # 중심 위도\n",
    "    solar_pos = get_solarposition(times, latitude=lat_center, longitude=lon)\n",
    "    solar_dict[(lat_min, lat_max)] = solar_pos\n",
    "    print(f\"✅ 저장 완료: {(lat_min, lat_max)} → {len(solar_pos)}시간치\")\n",
    "\n",
    "print(\"📦 solar_dict 전체 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78cf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시: (33, 34) 밴드에서 2023년 6월 21일 정오 시각의 solar position 확인\n",
    "check_time = pd.Timestamp(\"2023-06-21 12:00\", tz=tz)\n",
    "band = (33, 34)\n",
    "\n",
    "if check_time in solar_dict[band].index:\n",
    "    sol = solar_dict[band].loc[check_time]\n",
    "    print(f\"🔎 {band} @ {check_time} → Elev: {sol['apparent_elevation']:.2f}°, Azim: {sol['azimuth']:.2f}°\")\n",
    "else:\n",
    "    print(f\"⚠️ {check_time} 이 solar_dict[{band}]에 없음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04db079",
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, df in solar_dict.items():\n",
    "    print(f\"{band} → 시작: {df.index[0]}, 끝: {df.index[-1]}, 총 {len(df)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a11429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dem 위경도 좌표계 변환\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio\n",
    "\n",
    "src_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korean Peninsula\\Korea90m_GRS80.img\"\n",
    "dst_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korean Peninsula\\Korea90m_wgs84.tif\"  # 위경도 DEM 저장 경로\n",
    "\n",
    "with rasterio.open(src_path) as src:\n",
    "    dst_crs = \"EPSG:4326\"  # 위경도 좌표계\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "    )\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        \"crs\": dst_crs,\n",
    "        \"transform\": transform,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    })\n",
    "\n",
    "    with rasterio.open(dst_path, \"w\", **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):  # 밴드 수만큼 반복\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eae0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hillshade 개정판\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from pvlib.solarposition import get_solarposition\n",
    "  # 유틸 함수 분리 필요\n",
    "\n",
    "# ---------------------- 1. 사전 정의 ----------------------\n",
    "dem_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korean Peninsula\\Korea90m_wgs1984.tif\"\n",
    "output_dir = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade_3h\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "lat_band_edges = list(range(33, 39))  # (33~34), (34~35), ..., (37~38)\n",
    "\n",
    "# 시간 범위\n",
    "times = pd.date_range(start=\"2023-01-01 00:00\", end=\"2023-12-31 21:00\", freq=\"3H\", tz=\"Asia/Seoul\")\n",
    "\n",
    "# ---------------------- 2. DEM 정보 불러오기 ----------------------\n",
    "with rasterio.open(dem_path) as src:\n",
    "    dem = src.read(1)\n",
    "    meta = src.meta.copy()\n",
    "    transform = src.transform\n",
    "\n",
    "# ---------------------- 3. Slope / Aspect 계산 ----------------------\n",
    "slope, aspect = compute_slope_aspect(dem, transform)\n",
    "\n",
    "# ---------------------- 4. 위도 밴드별 마스크 생성 ----------------------\n",
    "masks = get_lat_band_masks(dem, transform, lat_band_edges)\n",
    "\n",
    "# ---------------------- 5. 위도 밴드별 Solar Position 사전 계산 ----------------------\n",
    "\n",
    "\n",
    "# ---------------------- 6. 시간 루프: Hillshade 생성 및 저장 ----------------------\n",
    "for dt in tqdm(times, desc=\"전체 Hillshade 생성 중\"):\n",
    "    combined = np.zeros_like(dem, dtype='uint8')\n",
    "    valid_band = False\n",
    "\n",
    "    for (lat_min, lat_max), mask in masks.items():\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sol = solar_dict[(lat_min, lat_max)].loc[dt]\n",
    "        except KeyError:\n",
    "            print(f\"⚠️ 시간 {dt} 에 대한 solar data 없음: {lat_min}-{lat_max}\")\n",
    "            continue\n",
    "\n",
    "        elev, azim = sol['apparent_elevation'], sol['azimuth']\n",
    "        if elev <= 0:\n",
    "            continue\n",
    "\n",
    "        hs = compute_hillshade(slope, aspect, azim, elev)\n",
    "        combined = np.where(mask, hs, combined)\n",
    "        valid_band = True\n",
    "\n",
    "    if not valid_band:\n",
    "        print(f\"⚠️ {dt} - 모든 밴드에서 유효 고도각 없음 → 파일 저장 생략\")\n",
    "        continue\n",
    "\n",
    "    # 저장\n",
    "    fname = f\"hillshade_combined_{dt.strftime('%Y-%m-%d_%H-%M')}.tif\"\n",
    "    out_path = os.path.join(output_dir, fname)\n",
    "    with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "        dst.write(combined, 1)\n",
    "\n",
    "    print(f\"✅ 저장 완료: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 생성 검증\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "raster_folder = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\"\n",
    "\n",
    "# ✅ 1) solar_dict에서 elevation > 0 인 시간 추출\n",
    "valid_times = set()\n",
    "\n",
    "for band_data in solar_dict.values():\n",
    "    for timestamp, row in band_data.iterrows():\n",
    "        if row['elevation'] > 0:\n",
    "            valid_times.add(timestamp.to_pydatetime())\n",
    "\n",
    "# ✅ 2) 폴더 내의 tif 파일 목록 가져오기\n",
    "existing_files = [f for f in os.listdir(raster_folder) if f.endswith(\".tif\")]\n",
    "\n",
    "# ✅ 3) 파일명에서 시간 추출\n",
    "existing_times = set()\n",
    "for filename in existing_files:\n",
    "    try:\n",
    "        # 파일명 예: hillshade_combined_2023-11-16_08-00.tif\n",
    "        dt_str = filename.replace(\"hillshade_combined_\", \"\").replace(\".tif\", \"\")\n",
    "        dt = datetime.strptime(dt_str, \"%Y-%m-%d_%H-%M\")\n",
    "        existing_times.add(dt)\n",
    "    except ValueError:\n",
    "        print(f\"⚠️ 잘못된 파일명 형식: {filename}\")\n",
    "\n",
    "# ✅ 4) 누락 파일: 유효 시간인데 존재하지 않는 파일\n",
    "missing_times = sorted(valid_times - existing_times)\n",
    "missing_files = [f\"hillshade_combined_{dt.strftime('%Y-%m-%d_%H-%M')}.tif\" for dt in missing_times]\n",
    "\n",
    "# ✅ 5) 불필요한 파일: 유효 시간이 아닌데 존재하는 파일\n",
    "extra_times = sorted(existing_times - valid_times)\n",
    "extra_files = [f\"hillshade_combined_{dt.strftime('%Y-%m-%d_%H-%M')}.tif\" for dt in extra_times]\n",
    "\n",
    "# ✅ 6) 출력\n",
    "if missing_files:\n",
    "    print(f\"❌ [총 {len(missing_files)}개] elevation > 0인데 파일 없음:\")\n",
    "    for f in missing_files:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"✅ elevation > 0인 시간대에 대해 모든 hillshade 파일이 존재합니다.\")\n",
    "\n",
    "if extra_files:\n",
    "    print(f\"\\n⚠️ [총 {len(extra_files)}개] elevation <= 0인데 파일이 존재함:\")\n",
    "    for f in extra_files:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"✅ elevation <= 0인 시간대에 대해 생성된 hillshade 파일이 없습니다.\")\n",
    "\n",
    "# ✅ 7) 결과 저장\n",
    "with open(os.path.join(raster_folder, \"missing_files_elev_gt0.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for name in missing_files:\n",
    "        f.write(name + \"\\n\")\n",
    "\n",
    "with open(os.path.join(raster_folder, \"extra_files_elev_le0.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for name in extra_files:\n",
    "        f.write(name + \"\\n\")\n",
    "\n",
    "print(\"\\n📁 누락/불필요한 파일 목록 저장 완료\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13591be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ elevation > 0을 만족하는 시간대를 담을 set\n",
    "valid_times = set()\n",
    "\n",
    "# 전체 시간대 기준 루프\n",
    "all_times = solar_dict[next(iter(solar_dict))].index  # solar_dict 중 하나에서 시간대 추출\n",
    "\n",
    "for time in all_times:\n",
    "    # 밴드 중 하나라도 elevation > 0이면 True\n",
    "    for band in solar_dict:\n",
    "        if solar_dict[band].loc[time, 'elevation'] > 0:\n",
    "            valid_times.add(time.to_pydatetime())\n",
    "            break  # 하나라도 조건 만족하면 다음 시간으로 넘어감\n",
    "\n",
    "# ✅ 결과 출력\n",
    "print(f\"☀️ elevation > 0인 고유 시간대 개수: {len(valid_times)}시간\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd719af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "with rasterio.open(r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\Korean Peninsula\\Korea90m_GRS80_to_wgs1984.tif\") as src:\n",
    "    print(\"CRS:\", src.crs)\n",
    "    print(\"Transform:\", src.transform)\n",
    "    width = src.width\n",
    "    height = src.height\n",
    "\n",
    "    lat_ul, lon_ul = src.xy(0, 0)  # upper-left\n",
    "    lat_lr, lon_lr = src.xy(height - 1, width - 1)  # lower-right\n",
    "\n",
    "    print(f\"UL (row=0, col=0):    lat={lat_ul:.6f}, lon={lon_ul:.6f}\")\n",
    "    print(f\"LR (row=H, col=W):   lat={lat_lr:.6f}, lon={lon_lr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ed0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{lat_min}-{lat_max} 밴드에서 True 셀 수: {np.sum(mask)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dt))\n",
    "print(solar_dict[(lat_min, lat_max)].index[:5])  # 예시로 인덱스 타입 확인\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea84ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hillshade window clipping\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import transform_bounds\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------- 설정 --------------------\n",
    "target_folder = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\"  # 기존 tif 파일이 있는 폴더 (여기에 덮어쓰기 저장됨)\n",
    "\n",
    "# 클리핑할 위도 범위 (WGS84 기준)\n",
    "target_lat_min = 33\n",
    "target_lat_max = 39\n",
    "\n",
    "# -------------------- 처리 --------------------\n",
    "for fname in tqdm(os.listdir(target_folder), desc=\"Windowing 진행 중\"):\n",
    "    if not fname.endswith('.tif'):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(target_folder, fname)\n",
    "\n",
    "    with rasterio.open(file_path) as src:\n",
    "        bounds = src.bounds\n",
    "        crs = src.crs\n",
    "\n",
    "        # 좌표계가 EPSG:4326(WGS84)이 아닐 경우 위도 기준으로 변환\n",
    "        if crs.to_epsg() != 4326:\n",
    "            wgs84_bounds = transform_bounds(crs, 'EPSG:4326', *bounds)\n",
    "        else:\n",
    "            wgs84_bounds = bounds\n",
    "\n",
    "        # 대상 경계와 겹치지 않으면 파일 삭제 후 skip\n",
    "        if wgs84_bounds[3] < target_lat_min or wgs84_bounds[1] > target_lat_max:\n",
    "            print(f\"🗑️ 삭제: {fname} - 위도 {wgs84_bounds[1]:.2f}~{wgs84_bounds[3]:.2f} → 범위 밖\")\n",
    "            os.remove(file_path)\n",
    "            continue\n",
    "\n",
    "        # 클리핑 범위 변환 (WGS84 → 원래 좌표계)\n",
    "        clip_bounds = transform_bounds('EPSG:4326', crs, bounds.left, target_lat_min, bounds.right, target_lat_max)\n",
    "        window = from_bounds(*clip_bounds, transform=src.transform)\n",
    "        window = window.round_offsets().round_lengths()\n",
    "\n",
    "        # 잘라낸 데이터 읽기\n",
    "        data = src.read(1, window=window)\n",
    "        transform = src.window_transform(window)\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'height': data.shape[0],\n",
    "            'width': data.shape[1],\n",
    "            'transform': transform\n",
    "        })\n",
    "\n",
    "    # 기존 파일 삭제 후 재저장\n",
    "    os.remove(file_path)\n",
    "    with rasterio.open(file_path, 'w', **meta) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "    print(f\"✅ 덮어쓰기 저장 완료: {fname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72350c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#window skip\n",
    "# Hillshade window clipping\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import transform_bounds\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------- 설정 --------------------\n",
    "target_folder = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\"  # 기존 tif 파일이 있는 폴더 (여기에 덮어쓰기 저장됨)\n",
    "\n",
    "# 클리핑할 위도 범위 (WGS84 기준)\n",
    "target_lat_min = 33\n",
    "target_lat_max = 39\n",
    "\n",
    "# -------------------- 처리 --------------------\n",
    "for fname in tqdm(os.listdir(target_folder), desc=\"Windowing 진행 중\"):\n",
    "    if not fname.endswith('.tif'):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(target_folder, fname)\n",
    "\n",
    "    with rasterio.open(file_path) as src:\n",
    "        bounds = src.bounds\n",
    "        crs = src.crs\n",
    "\n",
    "        # 좌표계가 EPSG:4326(WGS84)이 아닐 경우 위도 기준으로 변환\n",
    "        if crs.to_epsg() != 4326:\n",
    "            wgs84_bounds = transform_bounds(crs, 'EPSG:4326', *bounds)\n",
    "        else:\n",
    "            wgs84_bounds = bounds\n",
    "\n",
    "        lat_min, lat_max = wgs84_bounds[1], wgs84_bounds[3]\n",
    "\n",
    "        # 대상 경계와 겹치지 않으면 파일 삭제 후 skip\n",
    "        if lat_max < target_lat_min or lat_min > target_lat_max:\n",
    "            print(f\"🗑️ 삭제: {fname} - 위도 {lat_min:.2f}~{lat_max:.2f} → 범위 밖\")\n",
    "            os.remove(file_path)\n",
    "            continue\n",
    "\n",
    "        # 이미 클리핑 범위와 정확히 일치하는 경우 skip\n",
    "        if abs(lat_min - target_lat_min) < 0.01 and abs(lat_max - target_lat_max) < 0.01:\n",
    "           \n",
    "            continue\n",
    "\n",
    "        # 클리핑 범위 변환 (WGS84 → 원래 좌표계)\n",
    "        clip_bounds = transform_bounds('EPSG:4326', crs, bounds.left, target_lat_min, bounds.right, target_lat_max)\n",
    "        window = from_bounds(*clip_bounds, transform=src.transform)\n",
    "        window = window.round_offsets().round_lengths()\n",
    "\n",
    "        # 잘라낸 데이터 읽기\n",
    "        data = src.read(1, window=window)\n",
    "        transform = src.window_transform(window)\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'height': data.shape[0],\n",
    "            'width': data.shape[1],\n",
    "            'transform': transform\n",
    "        })\n",
    "\n",
    "    # 기존 파일 삭제 후 재저장\n",
    "    os.remove(file_path)\n",
    "    with rasterio.open(file_path, 'w', **meta) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "    print(f\"✅ 덮어쓰기 저장 완료: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad83e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "try:\n",
    "    with rasterio.open(r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\\hillshade_combined_2023-11-16_08-00.tif\") as src:\n",
    "        data = src.read(1)  # 읽기 시도\n",
    "        print(\"정상적으로 읽힘\")\n",
    "except Exception as e:\n",
    "    print(\"❌ 파일에 문제 있음:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de73b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1) 파일 경로\n",
    "shp_path      = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\naju_road_Hori.shp\"\n",
    "raster_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Hillshade_naju\"\n",
    "output_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\mask_naju_Hori\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 2) shapefile 불러오기 + CRS 지정\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "# 이미 CRS가 올바르게 기록돼 있지 않다면 강제 지정\n",
    "# “Korean 1985 / Modified Central Belt” = EPSG:2097\n",
    "if gdf.crs is None or gdf.crs.to_epsg() != 2097:\n",
    "    gdf = gdf.set_crs(epsg=2097, allow_override=True)\n",
    "\n",
    "for fname in os.listdir(raster_folder):\n",
    "    if not fname.lower().endswith(\".tif\"):\n",
    "        continue\n",
    "\n",
    "    in_rast  = os.path.join(raster_folder, fname)\n",
    "    out_rast = os.path.join(output_folder, f\"masked_{fname}\")\n",
    "\n",
    "    with rasterio.open(in_rast) as src:\n",
    "        # 3) shapefile → raster CRS 로 변환\n",
    "        vect = gdf.to_crs(src.crs)\n",
    "\n",
    "        # GeoJSON 포맷으로 변환\n",
    "        geoms = [mapping(geom) for geom in vect.geometry]\n",
    "\n",
    "        # 4) 마스킹 (픽셀의 중심이 폴리곤 내에 있어야 내부로 간주됨)\n",
    "        out_img, out_trans = mask(\n",
    "            src,\n",
    "            geoms,\n",
    "            all_touched=False,  \n",
    "            crop=False,\n",
    "            nodata=0,\n",
    "            filled=True\n",
    "        )\n",
    "\n",
    "        # 5) 메타데이터 갱신 및 저장\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            \"driver\":  \"GTiff\",\n",
    "            \"height\":  out_img.shape[1],\n",
    "            \"width\":   out_img.shape[2],\n",
    "            \"transform\": out_trans,\n",
    "            \"nodata\":  0\n",
    "        })\n",
    "\n",
    "        with rasterio.open(out_rast, \"w\", **meta) as dst:\n",
    "            dst.write(out_img)\n",
    "\n",
    "print(\"✅ 마스킹 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae172c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking valid cells csv\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 파일 경로 설정\n",
    "shp_path      = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\gangneung_road_Hori.shp\"\n",
    "raster_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Hillshade_gangneung\"\n",
    "output_csv    = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\gangneung_Hori_zerocell.csv\"\n",
    "\n",
    "# 2) shapefile 불러오기 및 CRS 지정 (Korean 1985 / Modified Central Belt, EPSG:2097)\n",
    "gdf = gpd.read_file(shp_path)\n",
    "if gdf.crs is None or gdf.crs.to_epsg() != 2097:\n",
    "    gdf = gdf.set_crs(epsg=2097, allow_override=True)\n",
    "\n",
    "# 3) 각 래스터 파일에 대해 마스킹 처리 후 통계 계산 (폴리곤 외부는 null값(np.nan)으로 처리)\n",
    "stats_list = []  # 결과 통계를 저장할 리스트\n",
    "raster_files = sorted([f for f in os.listdir(raster_folder) if f.lower().endswith('.tif')])\n",
    "\n",
    "for fname in tqdm(raster_files, desc=\"래스터 처리중\"):\n",
    "    raster_path = os.path.join(raster_folder, fname)\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # shapefile을 해당 래스터의 CRS로 재투영 후, GeoJSON 포맷으로 변환\n",
    "        vect = gdf.to_crs(src.crs)\n",
    "        geoms = [mapping(geom) for geom in vect.geometry]\n",
    "        \n",
    "        # 마스킹: 픽셀의 중심이 폴리곤 내에 있어야 내부로 간주\n",
    "        # filled=False로 해서 MaskedArray 형태로 받습니다.\n",
    "        out_img, out_trans = mask(\n",
    "            src,\n",
    "            geoms,\n",
    "            all_touched=False,\n",
    "            crop=False,\n",
    "            filled=False\n",
    "        )\n",
    "        \n",
    "    # out_img는 (1, rows, cols) 형태의 MaskedArray임.\n",
    "    masked = out_img[0]\n",
    "    \n",
    "    # 먼저 float32 타입으로 변환하고, 마스크된 영역을 np.nan으로 할당\n",
    "    data = masked.astype(\"float32\")\n",
    "    data[masked.mask] = np.nan\n",
    "    \n",
    "    # 유효한 셀(즉, np.nan이 아닌 셀) 수 계산\n",
    "    valid_count = np.count_nonzero(~np.isnan(data))\n",
    "    # 값이 0인 셀 수 계산 (np.nan은 비교 대상에서 제외)\n",
    "    zero_count = np.count_nonzero(data == 0)\n",
    "    \n",
    "    stats_list.append([fname, valid_count, zero_count])\n",
    "\n",
    "# 4) 결과 통계를 CSV 파일로 저장 (A열: 파일명, B열: 유효 셀 수, C열: 0인 셀 수)\n",
    "stats_df = pd.DataFrame(stats_list, columns=['RasterFile', 'ValidCellCount', 'ZeroCellCount'])\n",
    "stats_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"CSV 파일이 생성되었습니다:\", output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449da83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking valid cells csv v2\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "shp_path      = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\GIS\\SIGUNGU_CD.shp\"\n",
    "raster_folder = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\"\n",
    "output_csv    = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\GIS\\Solararea.csv\"\n",
    "\n",
    "# Shapefile 불러오기 및 CRS 확인\n",
    "gdf = gpd.read_file(shp_path)\n",
    "if gdf.crs is None or gdf.crs.to_epsg() != 2097:\n",
    "    gdf = gdf.set_crs(epsg=2097, allow_override=True)\n",
    "\n",
    "# SIGUNGU_CD 목록 추출\n",
    "sigungu_codes = gdf[\"SIGUNGU_CD\"].astype(str).tolist()\n",
    "\n",
    "# 결과 저장 리스트\n",
    "stats_list = []\n",
    "raster_files = sorted([f for f in os.listdir(raster_folder) if f.lower().endswith('.tif')])\n",
    "\n",
    "for fname in tqdm(raster_files, desc=\"래스터 처리중\"):\n",
    "    raster_path = os.path.join(raster_folder, fname)\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # 좌표계 변환\n",
    "        gdf_proj = gdf.to_crs(src.crs)\n",
    "\n",
    "        # 파일 결과 저장용 딕셔너리 (파일명 + 각 지역 유효 셀 수)\n",
    "        result = {\"RasterFile\": fname}\n",
    "\n",
    "        for idx, row in gdf_proj.iterrows():\n",
    "            sigungu_code = str(row[\"SIGUNGU_CD\"])\n",
    "            geom = [mapping(row.geometry)]\n",
    "\n",
    "            try:\n",
    "                out_img, _ = mask(\n",
    "                    src,\n",
    "                    geom,\n",
    "                    all_touched=False,\n",
    "                    crop=False,\n",
    "                    filled=False\n",
    "                )\n",
    "                masked = out_img[0].astype(\"float32\")\n",
    "                masked[masked.mask] = np.nan\n",
    "\n",
    "                non_zero_count = np.count_nonzero((~np.isnan(masked)) & (masked != 0))\n",
    "                result[sigungu_code] = non_zero_count\n",
    "\n",
    "            except Exception as e:\n",
    "                # 예외 발생 시 해당 구역은 0으로 간주\n",
    "                result[sigungu_code] = 0\n",
    "                print(f\"[경고] {fname}의 {sigungu_code} 영역 처리 중 오류 발생: {e}\")\n",
    "\n",
    "        stats_list.append(result)\n",
    "\n",
    "# 결과 DataFrame 생성 및 저장\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "stats_df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"CSV 파일이 생성되었습니다:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45831556",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271752c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가속화 Gemini V1\n",
    "# 개선된 코드 v1: rasterstats 사용\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 경로 설정 ---\n",
    "shp_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\GIS\\SIGUNGU_CD.shp\"\n",
    "raster_folder = r\"D:\\Junkyo\\2025\\WREC\\Korea_hillshade\"\n",
    "output_csv = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\GIS\\Solararea_improved.csv\"\n",
    "\n",
    "# --- Shapefile 불러오기 및 CRS 확인 ---\n",
    "gdf = gpd.read_file(shp_path, encoding='cp949') # 한글 필드를 위해 인코딩 추가\n",
    "# SHP 파일의 CRS를 EPSG:2097로 명시적 설정\n",
    "if gdf.crs is None or gdf.crs.to_epsg() != 2097:\n",
    "    gdf = gdf.set_crs(epsg=2097, allow_override=True)\n",
    "\n",
    "# 시군구 코드 목록을 나중에 DataFrame의 컬럼명으로 사용\n",
    "sigungu_codes = gdf[\"SIGUNGU_CD\"].astype(str).tolist()\n",
    "\n",
    "# --- 래스터 파일 목록 ---\n",
    "raster_files = sorted([f for f in os.listdir(raster_folder) if f.lower().endswith('.tif')])\n",
    "\n",
    "# --- 결과 저장을 위한 리스트 ---\n",
    "all_stats = []\n",
    "\n",
    "# --- 메인 프로세스 ---\n",
    "for fname in tqdm(raster_files, desc=\"래스터 처리중\"):\n",
    "    raster_path = os.path.join(raster_folder, fname)\n",
    "\n",
    "    try:\n",
    "        # zonal_stats 함수 한 번 호출로 모든 폴리곤의 통계 계산!\n",
    "        # 여기서 'count'는 0이 아닌 유효 픽셀의 개수를 의미합니다.\n",
    "        stats = zonal_stats(\n",
    "            gdf,\n",
    "            raster_path,\n",
    "            stats=\"count\",  # 0이 아닌 셀의 개수를 계산\n",
    "            geojson_out=True # 결과를 GeoJSON처럼 다루기 위함\n",
    "        )\n",
    "\n",
    "        # 결과 정리\n",
    "        result = {\"RasterFile\": fname}\n",
    "        for i, poly_stat in enumerate(stats):\n",
    "            sigungu_code = str(gdf.loc[i, \"SIGUNGU_CD\"])\n",
    "            # 'count' 값이 없을 경우(폴리곤이 래스터와 겹치지 않음 등) 0으로 처리\n",
    "            count = poly_stat['properties'].get('count', 0)\n",
    "            result[sigungu_code] = count\n",
    "        \n",
    "        all_stats.append(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[오류] {fname} 처리 중 오류 발생: {e}\")\n",
    "        # 오류 발생 시 해당 래스터 파일의 모든 값을 0으로 채움\n",
    "        error_result = {\"RasterFile\": fname}\n",
    "        for code in sigungu_codes:\n",
    "            error_result[code] = 0\n",
    "        all_stats.append(error_result)\n",
    "\n",
    "\n",
    "# --- 결과 DataFrame 생성 및 저장 ---\n",
    "stats_df = pd.DataFrame(all_stats)\n",
    "# 컬럼 순서를 'RasterFile' 다음 sigungu_codes 순서로 정렬\n",
    "stats_df = stats_df[[\"RasterFile\"] + sigungu_codes]\n",
    "stats_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\") # Excel에서 한글이 깨지지 않도록 utf-8-sig 사용\n",
    "\n",
    "print(\"CSV 파일이 성공적으로 생성되었습니다:\", output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile 생성 완료: C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\KMA_points.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_28104\\3211060487.py:26: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(output_shp, driver='ESRI Shapefile')\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Field 시작일 create as date field, though DateTime requested.\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Could not decode error message to UTF-8. Raw error: b\"Normalized/laundered field name: '\\xec\\xa7\\x80\\xec\\xa0\\x90\\xec\\xa3\\xbc\\xec\\x86\\x8c' to '\\xec\\xa7\\x80\\xec\\xa0\\x90\\xec\\xa3\\xbc\\xec'\"\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Could not decode error message to UTF-8. Raw error: b\"Normalized/laundered field name: '\\xea\\xb4\\x80\\xeb\\xa6\\xac\\xea\\xb4\\x80\\xec\\x84\\x9c' to '\\xea\\xb4\\x80\\xeb\\xa6\\xac\\xea\\xb4\\x80\\xec'\"\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Could not decode error message to UTF-8. Raw error: b\"Normalized/laundered field name: '\\xeb\\x85\\xb8\\xec\\x9e\\xa5\\xed\\x95\\xb4\\xeb\\xb0\\x9c\\xea\\xb3\\xa0\\xeb\\x8f\\x84(m)' to '\\xeb\\x85\\xb8\\xec\\x9e\\xa5\\xed\\x95\\xb4\\xeb'\"\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: '기압계(관측장비지상높이(m))' to '기압계('\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: '기온계(관측장비지상높이(m))' to '기온계('\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: '풍속계(관측장비지상높이(m))' to '풍속계('\n",
      "  ogr_write(\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: '강우계(관측장비지상높이(m))' to '강우계('\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#기상 관측 지점 피처 데이터 생성\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 엑셀 파일 경로\n",
    "excel_path = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\KMA_data.xlsx\"\n",
    "\n",
    "# 엑셀 파일 읽기 (기본 첫 시트)\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# 위도(F열), 경도(G열) 컬럼명 확인 후 수정 필요시 반영\n",
    "lat_col = df.columns[5]  # F열\n",
    "lon_col = df.columns[6]  # G열\n",
    "\n",
    "# 점(Point) geometry 생성\n",
    "geometry = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n",
    "\n",
    "# GeoDataFrame 생성\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# 저장할 shapefile 경로\n",
    "output_shp = r\"C:\\Users\\user\\Desktop\\Junkyo\\2025\\WREC\\KMA_points.shp\"\n",
    "\n",
    "# Shapefile로 저장\n",
    "gdf.to_file(output_shp, driver='ESRI Shapefile')\n",
    "\n",
    "print(\"Shapefile 생성 완료:\", output_shp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef99b451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 단일 래스터 마스킹 완료: C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Slope_Vert.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# 1) 입력 파일 경로\n",
    "shp_path    = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\gangneung_road_Vert.shp\"\n",
    "raster_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Slope.tif\"\n",
    "output_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Gangneung_Slope_Vert.tif\"\n",
    "\n",
    "# 2) shapefile 불러오기 + CRS 강제 지정(EPSG:2097)\n",
    "gdf = gpd.read_file(shp_path)\n",
    "if gdf.crs is None or gdf.crs.to_epsg() != 2097:\n",
    "    gdf = gdf.set_crs(epsg=2097, allow_override=True)\n",
    "\n",
    "# 3) rasterio로 래스터 열기 → 벡터를 래스터 CRS에 맞춰 재투영 → GeoJSON 리스트\n",
    "with rasterio.open(raster_path) as src:\n",
    "    vect = gdf.to_crs(src.crs)\n",
    "    geoms = [mapping(geom) for geom in vect.geometry]\n",
    "\n",
    "    # 4) 마스킹: all_touched=True, 내부 보존·외부 0\n",
    "    out_img, out_trans = mask(\n",
    "        src,\n",
    "        geoms,\n",
    "        all_touched=True,\n",
    "        crop=False,\n",
    "        nodata=0,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "    # 5) 메타데이터 갱신 (driver는 GTiff로)\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"driver\":   \"GTiff\",\n",
    "        \"height\":   out_img.shape[1],\n",
    "        \"width\":    out_img.shape[2],\n",
    "        \"transform\":out_trans,\n",
    "        \"nodata\":   0\n",
    "    })\n",
    "\n",
    "# 6) 결과 쓰기\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "    dst.write(out_img)\n",
    "\n",
    "print(\"✅ 단일 래스터 마스킹 완료:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b3c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경고: 래스터 파일의 갯수와 CSV 파일의 행 수가 일치하지 않습니다. 둘 중 작은 개수로 진행합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "래스터 처리중: 100%|██████████| 4400/4400 [01:46<00:00, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 래스터 파일의 발전량 계산 및 통계 CSV 생성 및 C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_gangneung_Hori 저장 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_raster_file(raster_path, SI, shading_factor, output_path):\n",
    "    \"\"\"\n",
    "    한 개의 래스터 파일에 대해 처리:\n",
    "      - 셀 값이 0이면 0, 그렇지 않으면 계산된 발전량으로 채움\n",
    "      - 발전량 = 0.22 * SI * (1 - shading_factor) * 450\n",
    "      - 반환값: non_zero_count, total_value\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        arr = src.read(1)  # 단일 밴드 읽기\n",
    "        meta = src.meta.copy()\n",
    "    \n",
    "    # 계산: 모든 non-zero 셀에 대해 동일한 발전량을 계산합니다.\n",
    "    gen_value = 0.22 * SI * (1 - shading_factor) * 450\n",
    "    result = np.where(arr == 0, 0, gen_value)\n",
    "\n",
    "    # 통계 값 계산: 셀이 0이 아닌 셀들의 갯수와, 전체 셀의 값 합계\n",
    "    nonzero_count = np.count_nonzero(result)\n",
    "    total_value = np.sum(result)\n",
    "\n",
    "    # 메타데이터 업데이트 (GeoTIFF 쓰기용)\n",
    "    meta.update({\n",
    "        \"dtype\": \"float32\",\n",
    "        \"driver\": \"GTiff\"\n",
    "    })\n",
    "    \n",
    "    # 결과 저장\n",
    "    with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "        dst.write(result.astype(np.float32), 1)\n",
    "    \n",
    "    return nonzero_count, total_value\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. 파일 경로 설정\n",
    "hillshade_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\mask_gangneung_Hori\"\n",
    "csv_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\tmy\\Study_tmy\\Gangneung_samcsv.csv\" # CSV 파일 (UTF-8 인코딩)\n",
    "output_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_gangneung_Hori\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ------------------------------------\n",
    "# 2. CSV 파일 로드 (헤더가 3번째 행에 있다고 가정)\n",
    "solar_df = pd.read_csv(csv_path, encoding='utf-8', header=2)\n",
    "\n",
    "required_columns = ['Irradiance', 'SelfShading']\n",
    "for col in required_columns:\n",
    "    if col not in solar_df.columns:\n",
    "        raise ValueError(f\"CSV 파일에 '{col}' 열이 없습니다.\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 3. 폴더 내의 래스터 파일들을 정렬된 순서대로 읽기\n",
    "raster_files = sorted([f for f in os.listdir(hillshade_folder) if f.lower().endswith('.tif')])\n",
    "if len(raster_files) != len(solar_df):\n",
    "    print(\"경고: 래스터 파일의 갯수와 CSV 파일의 행 수가 일치하지 않습니다. 둘 중 작은 개수로 진행합니다.\")\n",
    "\n",
    "n_files = min(len(raster_files), len(solar_df))\n",
    "\n",
    "# ------------------------------------\n",
    "# 결과 통계 저장 리스트 (각 행: [래스터파일명, 0이 아닌 셀 갯수, 전체 셀값 합계])\n",
    "stats_list = []\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. 각 래스터 파일에 대해 처리\n",
    "for i in tqdm(range(n_files), desc=\"래스터 처리중\"):\n",
    "    raster_file = raster_files[i]\n",
    "    raster_path = os.path.join(hillshade_folder, raster_file)\n",
    "    \n",
    "    # CSV의 i번째 행값 추출\n",
    "    row = solar_df.iloc[i]\n",
    "    \n",
    "    # Solar Irradiance (SI) 계산: GHI, DNI, DHI 합산\n",
    "    SI = row['Irradiance']\n",
    "    shading_factor = row['SelfShading']\n",
    "    \n",
    "    # 출력 파일 경로 생성 (파일명 앞에 \"processed_\" 접두사 추가)\n",
    "    output_path = os.path.join(output_folder, f\"processed_{raster_file}\")\n",
    "    \n",
    "    # 한 래스터 파일 처리 및 통계 계산\n",
    "    nonzero_count, total_value = process_raster_file(raster_path, SI, shading_factor, output_path)\n",
    "    \n",
    "    # 통계 정보 리스트에 추가: 파일명, 0이 아닌 셀 갯수, 전체 값의 합계\n",
    "    stats_list.append([raster_file, nonzero_count, total_value])\n",
    "\n",
    "# ------------------------------------\n",
    "# 5. 통계 결과를 새로운 CSV 파일로 저장\n",
    "stats_df = pd.DataFrame(stats_list, columns=['RasterFile', 'NonZeroCount', 'TotalValue'])\n",
    "stats_csv_path = os.path.join(output_folder, \"raster_statistics.csv\")\n",
    "stats_df.to_csv(stats_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"모든 래스터 파일의 발전량 계산 및 통계 CSV 생성 및 {output_folder} 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51016b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "래스터 처리중: 100%|██████████| 4400/4400 [01:59<00:00, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 래스터 파일의 발전량 통계 CSV 생성 및 C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_naju_Hori에 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_raster_file(raster_path, SI, shading_factor):\n",
    "    \"\"\"\n",
    "    한 개의 래스터 파일에 대해 처리:\n",
    "      - 셀 값이 0이면 0, 그렇지 않으면 계산된 발전량으로 채움\n",
    "      - 발전량 = 0.22 * SI * (1 - shading_factor) * 450\n",
    "      - 반환값: non_zero_count, total_value\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        arr = src.read(1)  # 단일 밴드 읽기\n",
    "    \n",
    "    # 발전량 계산: 모든 non-zero 셀에 대해 동일한 값\n",
    "    gen_value = 0.9* 0.22 * SI * (shading_factor) * 450\n",
    "    result = np.where(arr == 0, 0, gen_value)\n",
    "    \n",
    "    # 통계 값 계산: 셀이 0이 아닌 셀들의 갯수와, 전체 셀의 합계\n",
    "    nonzero_count = np.count_nonzero(result)\n",
    "    total_value = np.sum(result)\n",
    "    \n",
    "    return nonzero_count, total_value\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. 파일 경로 설정\n",
    "hillshade_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\mask_naju_Hori\"\n",
    "csv_path = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\tmy\\Study_tmy\\Naju_samcsv.csv\"  # CSV 파일 (UTF-8 인코딩)\n",
    "output_folder = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_naju_Hori\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ------------------------------------\n",
    "# 2. CSV 파일 로드 (헤더가 3번째 행에 있다고 가정)\n",
    "solar_df = pd.read_csv(csv_path, encoding='utf-8', header=2)\n",
    "\n",
    "required_columns = ['Irradiance', 'Vable']\n",
    "for col in required_columns:\n",
    "    if col not in solar_df.columns:\n",
    "        raise ValueError(f\"CSV 파일에 '{col}' 열이 없습니다.\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 3. 폴더 내의 래스터 파일들을 정렬된 순서대로 읽기\n",
    "raster_files = sorted([f for f in os.listdir(hillshade_folder) if f.lower().endswith('.tif')])\n",
    "if len(raster_files) != len(solar_df):\n",
    "    print(\"경고: 래스터 파일의 갯수와 CSV 파일의 행 수가 일치하지 않습니다. 둘 중 작은 개수로 진행합니다.\")\n",
    "\n",
    "n_files = min(len(raster_files), len(solar_df))\n",
    "\n",
    "# ------------------------------------\n",
    "# 결과 통계 저장 리스트 (각 행: [래스터파일명, 0이 아닌 셀 갯수, 전체 셀값 합계])\n",
    "stats_list = []\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. 각 래스터 파일에 대해 처리 (tif 파일은 생성하지 않고 통계만 계산)\n",
    "for i in tqdm(range(n_files), desc=\"래스터 처리중\"):\n",
    "    raster_file = raster_files[i]\n",
    "    raster_path = os.path.join(hillshade_folder, raster_file)\n",
    "    \n",
    "    # CSV의 i번째 행값 추출\n",
    "    row = solar_df.iloc[i]\n",
    "    \n",
    "    SI = row['Irradiance']\n",
    "    shading_factor = row['SelfShading']\n",
    "    \n",
    "    # 한 래스터 파일 처리 및 통계 계산 (tif 파일은 별도 출력하지 않음)\n",
    "    nonzero_count, total_value = process_raster_file(raster_path, SI, shading_factor)\n",
    "    \n",
    "    # 통계 정보 리스트에 추가: 파일명, 0이 아닌 셀 갯수, 전체 값 합계\n",
    "    stats_list.append([raster_file, nonzero_count, total_value])\n",
    "\n",
    "# ------------------------------------\n",
    "# 5. 통계 결과를 새로운 CSV 파일로 저장\n",
    "stats_df = pd.DataFrame(stats_list, columns=['RasterFile', 'NonZeroCount', 'TotalValue'])\n",
    "stats_csv_path = os.path.join(output_folder, \"raster_statistics.csv\")\n",
    "stats_df.to_csv(stats_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"모든 래스터 파일의 발전량 통계 CSV 생성 및 {output_folder}에 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78cc9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 생성되었습니다: C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_gangneung_Hori\\PVgen_GHori.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "NH=4600 \n",
    "NV=10490\n",
    "GH=6300\n",
    "GV=6700\n",
    "\n",
    "# 1. CSV 입력 및 출력 경로 설정\n",
    "csv_input = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\tmy\\Study_tmy\\Gangneung_samcsv.csv\"\n",
    "csv_output = r\"C:\\Users\\82105\\Desktop\\Junkyo\\2025\\PVSEC\\GIS_preprocessing\\Power_gangneung_Hori\\PVgen_GHori.csv\"\n",
    "\n",
    "# 2. 헤더가 3번째 행에 있으므로 header=2로 읽기\n",
    "df = pd.read_csv(csv_input, encoding='utf-8', header=2)\n",
    "\n",
    "# 3. 필요한 열 추출: 'Irradiance', 'Hable', 'Month', 'Day', 'Hour'\n",
    "required_cols = ['Irradiance', 'Hable', 'Month', 'Day', 'Hour']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(\"필요한 열이 누락되어 있습니다.\")\n",
    "df_filtered = df[required_cols].copy()\n",
    "\n",
    "# 4. 발전량 계산\n",
    "# PVgen = 0.22 * 0.9 * Irradiance * Hable * 4500 * 20\n",
    "df_filtered['PVgen'] = 0.22 * 0.9 * df_filtered['Irradiance'] * df_filtered['Hable'] * GH * 20\n",
    "\n",
    "# 5. Timestamp 문자열 생성 (year는 모두 2023, Month, Day, Hour는 두 자리 형식)\n",
    "df_filtered['Timestamp'] = (\n",
    "    '2023-' +\n",
    "    df_filtered['Month'].astype(int).astype(str).str.zfill(2) + '-' +\n",
    "    df_filtered['Day'].astype(int).astype(str).str.zfill(2) + '-' +\n",
    "    df_filtered['Hour'].astype(int).astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "# 6. 결과 DataFrame 구성\n",
    "# A열: Time (Timestamp), B열: PVgen\n",
    "result_df = df_filtered[['Timestamp', 'PVgen']].copy()\n",
    "result_df.columns = ['Time', 'PVgen']\n",
    "\n",
    "# 7. 추가 기능: \n",
    "# 7.1 C열 (\"kWh\"): PVgen의 0.001배 값\n",
    "result_df['kWh'] = result_df['PVgen'] * 0.001\n",
    "\n",
    "# 7.2 D열 (\"kWh/m2\"): kWh 값을 4500*20으로 나눈 값\n",
    "result_df['kWh/m2'] = result_df['kWh'] /  (GH * 20)\n",
    "\n",
    "# 8. CSV 파일로 출력\n",
    "result_df.to_csv(csv_output, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"CSV 파일이 생성되었습니다: {csv_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99adff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
